{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from performance_profile import get_workloads_time_to_target\n",
    "from performance_profile import BASE_WORKLOADS\n",
    "from scipy import stats\n",
    "from plotting_utils import PLOT_STYLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from disk\n",
    "SELF_TUNING = True\n",
    "results_path = '../../results/'\n",
    "file_path = 'self_tuning/self_tuning_scoring_results.txt' if SELF_TUNING else 'external_tuning/external_tuning_scoring_results.txt'\n",
    "RESULTS_FILE = os.path.join(results_path, file_path)\n",
    "\n",
    "with open(RESULTS_FILE, 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Expecting 5 studies for workload librispeech_conformer_layernorm_pytorch but found 4 studies for AdamG.\n",
      "WARNING:absl:Expecting 14 workloads but found 12 workloads for sinv6_75.\n",
      "WARNING:absl:Expecting 14 workloads but found 12 workloads for sinv6.\n"
     ]
    }
   ],
   "source": [
    "times = {}\n",
    "for submission in results.keys():\n",
    "    # Compute median over runtimes for both training algorithms\n",
    "    times[submission] = get_workloads_time_to_target(\n",
    "        results[submission],\n",
    "        submission,\n",
    "        time_col=\"score\",\n",
    "        self_tuning_ruleset=SELF_TUNING,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BUDGETS = {\n",
    "    'criteo1tb': 7703,\n",
    "    'fastmri': 8859,\n",
    "    'imagenet_resnet': 63_008,\n",
    "    'imagenet_vit': 77_520,\n",
    "    'librispeech_conformer': 61_068,\n",
    "    'librispeech_deepspeech': 55_506,\n",
    "    'ogbg': 18_477,\n",
    "    'wmt': 48_151,\n",
    "}\n",
    "\n",
    "def replace_inf(row):\n",
    "  \"\"\"Replace ifs with maximum runtime budget (+1 second).\n",
    "\n",
    "  Args:\n",
    "      row (pd.Series): The original row.\n",
    "\n",
    "  Returns:\n",
    "      pd.Series: The row with infs replaced.\n",
    "  \"\"\"\n",
    "  workload_name = row.name\n",
    "  # Factor of 3 for self-tuning ruleset\n",
    "  factor = 3 if SELF_TUNING else 1\n",
    "  max_runtime_workload = factor * MAX_BUDGETS[workload_name]\n",
    "  row.replace(np.inf, max_runtime_workload + 1, inplace=True)\n",
    "  row.replace(np.nan, max_runtime_workload + 1, inplace=True)\n",
    "  return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "workload & speedup \\\\\n",
      "submission &  \\\\\n",
      "\\midrule\n",
      "\\sfadam & +7.76\\% \\\\\n",
      "\\baseline & -0.00\\% \\\\\n",
      "\\nadamwseq & -92.44\\% \\\\\n",
      "\\sinvnum & -157.67\\% \\\\\n",
      "\\sinv & -168.63\\% \\\\\n",
      "\\adamg & -294.17\\% \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine all times into one dataframe\n",
    "merged_df = pd.concat(times)\n",
    "\n",
    "# Drop the first index level\n",
    "merged_df = merged_df.droplevel(level=0)\n",
    "\n",
    "# Only keep base workloads\n",
    "workloads_to_keep = [col for col in merged_df.columns if col in BASE_WORKLOADS]\n",
    "merged_df = merged_df[workloads_to_keep]\n",
    "\n",
    "# Replace infs with maximum runtime budget (+1 second)\n",
    "merged_df = merged_df.apply(replace_inf, axis=0)\n",
    "\n",
    "# Get the baseline runtimes for each workload\n",
    "baseline_runtimes = merged_df.loc[\"prize_qualification_baseline\"]\n",
    "\n",
    "# Compute speedup vs. baseline\n",
    "relative_runtimes = merged_df.div(baseline_runtimes, axis=1)\n",
    "\n",
    "# Compute geometric mean speedup\n",
    "merged_df[\"geometric_mean\"] = stats.gmean(relative_runtimes, axis=1)\n",
    "\n",
    "# Sort by speedup\n",
    "merged_df.sort_values(by=\"geometric_mean\", ascending=True, inplace=True)\n",
    "\n",
    "speedups = (merged_df[\"geometric_mean\"] - 1) * 100\n",
    "speedups = speedups.apply(lambda x: f\"-{x:.2f}\\%\" if x >= 0 else f\"+{abs(x):.2f}\\%\")\n",
    "merged_df[\"speedup\"] = speedups\n",
    "\n",
    "# Drop the geometric mean column and workloads\n",
    "merged_df = merged_df.drop(columns=[\"geometric_mean\"])\n",
    "merged_df = merged_df.drop(columns=workloads_to_keep)\n",
    "\n",
    "# Beautify the submission names\n",
    "merged_df.index = merged_df.index.map(lambda x: PLOT_STYLE.get(x, {}).get('command', x))\n",
    "\n",
    "print(merged_df.to_latex())\n",
    "# merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algoperf_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
